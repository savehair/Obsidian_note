# 1 聚类分析 (Cluster Analysis)
聚类分析的核心是通过距离计算，将相似的样品归为一类。
## 1.1 系统聚类法 (Hierarchical Clustering)
这是最常见的计算题考点。
- **步骤1：初始化** 将 $n$ 个样品各自看作一类，计算两两之间的距离矩阵（通常使用欧氏距离）。
- **步骤2：合并最小距离** 在距离矩阵中找到**最小**的数值，将对应的两类合并为一个新类。
- **步骤3：更新距离（关键步骤）** 计算新合并的类与其他剩余类之间的距离。常用公式如下：
    - **最短距离法**：$D(New, K) = \min(D(A, K), D(B, K))$
    - **最长距离法**：$D(New, K) = \max(D(A, K), D(B, K))$
    - **重心法**、**类平均法**等也有对应公式。
- **步骤4：迭代** 重复步骤2和3，直到所有样品归为一大类，最后画出聚类谱系图。
## 1.2 快速聚类法 (K-Means)
- **步骤1：选中心** 任取 $k$ 个初始中心（通常题目会给定）。
- **步骤2：分配** 计算每个样品到这 $k$ 个中心的距离，将样品划入距离**最近**的那个簇。
- **步骤3：更新中心** 重新计算每个簇的**均值**（重心），作为新的中心点。
- **步骤4：停止** 重复上述过程，直到中心点不再变化或分类结果不再改变。

---
# 2 综合评价 (Comprehensive Evaluation) - 层次分析法 (AHP)
AHP是综合评价中的核心计算内容，涉及矩阵运算。
- **步骤1：构造判断矩阵** 建立矩阵 $A = (a_{ij})_{m \times m}$，其中 $a_{ij}$ 表示指标 $i$ 相对于指标 $j$ 的重要程度（如 $3$ 表示稍微重要，$1/3$ 表示稍微不重要）。
- **步骤2：计算权重 (和积法或方根法)** 资料中推荐**几何平均法（方根法）**：
    1. **按行相乘**：计算每行元素的乘积 $M_i = \prod_{j=1}^m a_{ij}$。
    2. **开根号**：计算几何平均数 $\overline{a}_i = \sqrt[m]{M_i}$。
    3. **归一化**：计算权重向量 $W = (w_1, ..., w_m)^T$，其中 $w_i = \frac{\overline{a}_i}{\sum_{k=1}^m \overline{a}_k}$。
- **步骤3：一致性检验 (必考)**
    1. **求最大特征根**：$\lambda_{max} \approx \frac{1}{m} \sum_{i=1}^m \frac{(AW)_i}{w_i}$，其中 $(AW)_i$ 是向量 $AW$ 的第 $i$ 个分量。
    2. **计算一致性指标**：$CI = \frac{\lambda_{max} - m}{m - 1}$。
    3. **计算比率**：$CR = \frac{CI}{RI}$（$RI$ 查表可得）。若 $CR < 0.10$，则通过检验。
- **步骤4：计算总分** 综合得分 $S = \sum w_i z_i$（$z_i$ 为标准化后的指标值）。

---
# 3 主成分分析 (PCA)
PCA 的核心是对协方差矩阵进行谱分解。
- **步骤1：数据标准化** 为了消除量纲影响，通常先将数据标准化（均值为0，方差为1）。
- **步骤2：求特征值与特征向量** 计算协方差矩阵 $\Sigma$（或相关系数矩阵 $R$）的特征根 $\lambda_1 \ge \lambda_2 \ge \dots \ge 0$ 及对应的单位特征向量 $u_1, u_2, \dots$。
- **步骤3：确定主成分个数** 计算**累计方差贡献率**：$G(m) = \frac{\sum_{i=1}^m \lambda_i}{\sum_{j=1}^p \lambda_j}$。通常要求 $G(m) > 80\%$ 或 85% 来确定保留的主成分个数 $m$。
- **步骤4：写出主成分表达式** 第 $i$ 个主成分 $y_i$ 是原始变量 $x$ 的线性组合，系数即为特征向量 $u_i$： $$y_i = u_{i1}x_1 + u_{i2}x_2 + \dots + u_{ip}x_p$$。 _(注：主成分的方差即为对应的特征根 $\lambda_i$)_。

---
# 4 因子分析 (Factor Analysis)
计算步骤与 PCA 类似，但更强调“载荷矩阵”的估计。
- **步骤1：分解矩阵** 同样对协方差矩阵 $\Sigma$ 或相关矩阵 $R$ 进行特征值分解。
- **步骤2：估计因子载荷矩阵 $A$** 这是与 PCA 最大的区别。选取前 $m$ 个特征根和特征向量，载荷矩阵 $A$ 的第 $j$ 列为： $$a_j = \sqrt{\lambda_j} u_j$$ 即 $A = (\sqrt{\lambda_1}u_1, \sqrt{\lambda_2}u_2, \dots, \sqrt{\lambda_m}u_m)$。
- **步骤3：计算共同度** 变量 $x_i$ 的共同度 $h_i^2$ 等于载荷矩阵 $A$ 中第 $i$ 行元素的平方和，反映了公共因子对该变量的解释能力。
- **步骤4：因子旋转 (概念)** 如果载荷矩阵难以解释，通过正交旋转使因子意义更明确（计算题通常只要求到未旋转的载荷矩阵）。

---
# 5 典型相关分析 (CCA)
研究**两组**变量（向量 $x$ 和向量 $y$）之间的相关性。
- **步骤1：构建分块矩阵** 计算协方差矩阵并分块：$\Sigma_{11}$ (x的方差), $\Sigma_{22}$ (y的方差), $\Sigma_{12}$ 和 $\Sigma_{21}$ (xy的协方差)。
- **步骤2：构造矩阵 $M$** 计算矩阵 $M = \Sigma_{11}^{-1} \Sigma_{12} \Sigma_{22}^{-1} \Sigma_{21}$。
- **步骤3：求特征根** 计算 $M$ 的特征根 $\lambda_1 \ge \lambda_2 \dots$。 **注意**：这里的 $\sqrt{\lambda_i}$ 即为第 $i$ 对**典型相关系数**。
- **步骤4：求典型变量系数** 计算对应的特征向量，即为典型变量（线性组合）的系数 $a$ 和 $b$。

---
# 6 判别分析 (Discriminant Analysis)
已知类别，对新样本进行分类。
## 6.1 Fisher 判别 (线性判别)
- **步骤1：计算统计量** 计算各类别的均值向量 $\bar{X}_1, \bar{X}_2$ 和类内协方差矩阵 $S_1, S_2$。
- **步骤2：计算联合协方差** $$S_{pooled} = \frac{(n_1-1)S_1 + (n_2-1)S_2}{n_1+n_2-2}$$。
- **步骤3：求判别系数** $$a = S_{pooled}^{-1} (\bar{X}_1 - \bar{X}_2)$$。
- **步骤4：建立判别函数与规则** 判别函数 $y(x) = a'x$。 计算临界值 $y_0 = \frac{1}{2}a'(\bar{X}_1 + \bar{X}_2)$。若 $y(x) > y_0$ 归为一类，反之归为另一类（具体符号取决于相减顺序）。
## 6.2 Bayes 判别 (概率判别)
- **情形1：协方差矩阵不同 ($\Sigma_1 \neq \Sigma_2$)** 使用**二次判别函数** $Z(j|x)$。需要计算 $\ln|\Sigma_j|$ 和马氏距离 $(x-\mu_j)'\Sigma_j^{-1}(x-\mu_j)$。选择 $Z$ 值**最大**的一类。
- **情形2：协方差矩阵相同 ($\Sigma_1 = \Sigma_2$)** 使用**线性判别函数** $Y(j|x)$： $$Y(j|x) = \ln q_j - \frac{1}{2}\mu_j'\Sigma^{-1}\mu_j + x'\Sigma^{-1}\mu_j$$ 其中 $q_j$ 是先验概率。选择 $Y$ 值**最大**的一类。

---

**复习建议**：对于计算题，重点练习 **AHP的权重计算与一致性检验**、**PCA的特征值贡献率与表达式**、以及 **Fisher判别的系数求解**。这些步骤固定且逻辑清晰，是主要的得分点。