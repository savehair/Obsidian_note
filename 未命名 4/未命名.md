根据您提供的教材（特别是赵卫东、董亮编著的《机器学习》第2版）及相关课件内容，**关联规则（Association Rules）** 是一种常用的无监督学习方法，主要用于从大量数据中发现变量之间的有趣关系。它最经典的案例是“啤酒与尿布”的购物篮分析。

以下是关于关联规则的核心知识点梳理：
## 0.1 核心概念与度量指标

关联规则挖掘主要依赖三个核心指标来衡量规则的强度和有效性：**支持度**、**置信度**和**提升度**。

*   **定义**：假设有一组事务数据集，关联规则形如 $X \rightarrow Y$，表示“如果购买了商品 X，往往也会购买商品 Y”。
*   **支持度 (Support)**：
    *   **含义**：项集（如商品组合）在所有事务中出现的概率。衡量规则的普遍性。
    *   **公式**：$Support(A \cup B) = \frac{\text{Freq}(A \cap B)}{N}$，其中 $N$ 是总事务数。
    *   *注*：通常需要设定一个“最小支持度”阈值，低于此阈值的规则被认为是偶然发生的，不予考虑。
*   **置信度 (Confidence)**：
    *   **含义**：在包含 A 的事务中，同时也包含 B 的条件概率。衡量规则的准确性。
    *   **公式**：$Confidence(A \rightarrow B) = P(B|A) = \frac{Support(A \cup B)}{Support(A)} = \frac{\text{Freq}(A \cap B)}{\text{Freq}(A)}$。
    *   *考试计算题提示*：在您提供的历年单选题（第6题）中，考查了该概念：已知包含 X 和 Y 的事务数为 30，包含 X 的事务数为 50，则置信度为 $30/50 = 0.6$。
*   **提升度 (Lift)**：
    *   **含义**：判断规则是否有实际价值。它衡量了“购买 A”对“购买 B”概率的提升程度。
    *   **公式**：$Lift(A \rightarrow B) = \frac{Confidence(A \rightarrow B)}{Support(B)} = \frac{P(B|A)}{P(B)}$。
    *   **判别**：
        *   Lift > 1：正相关，规则有效（A 的出现提高了 B 出现的概率）。
        *   Lift = 1：相互独立，无关联。
        *   Lift < 1：负相关（A 的出现降低了 B 出现的概率）。

### 0.1.1 经典算法

为了高效地挖掘出满足最小支持度和最小置信度的规则，主要有以下几种算法：

#### 0.1.1.1 (1) Apriori 算法
*   **原理**：基于频繁项集的先验性质——**“频繁项集的非空子集也一定是频繁的；非频繁项集的超集一定是非频繁的”**。利用这一性质进行**剪枝**，减少搜索空间。
*   **流程**：
    1.  扫描数据库，统计 1-项集的支持度，剪去低于阈值的项。
    2.  组合生成 2-项集，再次扫描计算支持度，剪枝。
    3.  迭代直到无法生成更多的频繁项集。
*   **缺点**：需要多次扫描数据库（I/O 开销大），且会产生大量的候选项集，效率较低。

#### 0.1.1.2 (2) FP-growth 算法 (Frequent Pattern Growth)
*   **原理**：为了解决 Apriori 效率低的问题提出。它不产生候选项集，而是通过构建一棵 **FP 树（频繁模式树）** 来压缩数据。
*   **流程**：
    1.  第一次扫描：统计词频，过滤非频繁项，按支持度降序排列。
    2.  第二次扫描：构建 FP 树。
    3.  在 FP 树上递归挖掘频繁项集。
*   **优点**：只需**两次**扫描数据库，速度通常比 Apriori 快一个数量级。

#### 0.1.1.3 (3) Eclat 算法
*   **原理**：采用**垂直数据格式**（倒排索引），将“事务-项”转化为“项-事务ID列表”。
*   **特点**：通过计算事务 ID 集合的**交集**来快速计算支持度，深度优先搜索。缺点是交集运算量大且占用内存。

### 0.1.2 应用场景

*   **购物篮分析**：发现“啤酒与尿布”通过数据挖掘被摆放在一起销售的规律。
*   **推荐系统**：
    *   **基于关联规则的推荐**：分析用户购买记录，发现 $\{A, B\} \rightarrow \{C\}$ 的规则。如果用户买了 A 和 B，就推荐 C。
    *   相比协同过滤，它更侧重于物品间的强关联逻辑，但可能面临冷启动和计算复杂度高的问题。
*   **其他**：医疗诊断（症状与疾病的关联）、网页浏览分析等。

### 0.1.3 复习建议

根据您的复习资料，关于关联规则建议重点掌握以下内容：
1.  **计算题**：给出一个简单的事务数据集（如5-10条记录），能够手动计算某条规则的 **Support**、**Confidence** 和 **Lift**。
2.  **概念辨析**：理解 Apriori 算法的“剪枝”原理（为什么非频繁项集的超集可以直接删除）。
3.  **算法对比**：知道 Apriori（多次扫描，产生候选集）与 FP-growth（两次扫描，构建树，不产生候选集）的主要区别。