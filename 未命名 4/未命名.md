根据您提供的教材和课件资料，机器学习中常用的训练集划分方式主要包括**留出法**、**交叉验证法**和**自助法**。它们在计算代价、评估稳定性和适用场景上各有优缺点：

### 0.1.1 留出法 (Hold-out Method)

直接将数据集 $D$ 划分为两个互斥的集合：训练集 $S$ 和测试集 $T$（例如按 7:3 或 8:2 比例划分）。

- **优点**：
    - **简单高效**：逻辑清晰，只需进行一次划分和训练，计算开销极低，是处理**大规模数据集**时的首选方法。
- **缺点**：
    - **结果存在随机性**：评估结果很大程度上取决于具体的划分方式。单次划分可能无法代表数据的整体分布，导致评估结果不够稳定（高方差）。
    - **数据利用率低**：必须保留一部分数据作为测试集（通常占 20%-30%），这部分数据无法用于训练模型。在数据量较少时，这会导致训练集与原始数据集差异较大，从而引入评估偏差。

### 0.1.2 交叉验证法 (Cross-Validation)

将数据集划分为 $k$ 个大小相似的互斥子集，每次用 $k-1$ 个子集的并集作为训练集，余下的那个作为测试集，重复 $k$ 次（即 **k折交叉验证**）。

- **优点**：
    - **评估结果稳定**：通过多次划分和测试取平均值，有效降低了因单次划分带来的随机性，结果更能反映模型的真实泛化能力。
    - **数据利用率高**：每个样本都有机会作为训练集和测试集，充分利用了有限的数据资源。
- **缺点**：
    - **计算代价高**：需要训练 $k$ 次模型，计算开销是留出法的 $k$ 倍，对于大数据集或训练缓慢的模型来说负担较重。
- **特例：留一法 (Leave-One-Out, LOO)**
    - _特点_：$k$ 等于样本总数，每次只留一个样本做测试。
    - _优点_：不受随机划分影响，结果最准确（无偏估计）。
    - _缺点_：计算开销极大，仅适用于**极小数据集**。

### 0.1.3 自助法 (Bootstrapping)

对包含 $m$ 个样本的数据集进行 $m$ 次**有放回**的随机采样，得到训练集。未被采样的样本（约占 36.8%）作为测试集（包外估计）。

- **优点**：
    - **解决小样本难题**：在数据集较小、难以有效划分训练/测试集时非常有用，能从有限数据中产生多个不同的训练集。
    - **集成学习的基础**：是 Bagging（如随机森林）等集成学习算法的核心，通过引入样本扰动增加模型多样性。
- **缺点**：
    - **引入估计偏差**：由于采用有放回采样，产生的数据集改变了原始数据的分布，这会引入估计偏差。因此，在数据量充足时，通常首选留出法或交叉验证法。

### 0.1.4 总结建议

- **数据量充足**：优先使用**留出法**，兼顾效率与效果。
- **数据量适中**：优先使用**k折交叉验证**（如 10折），评估结果更可靠。
- **数据量极少**：考虑使用**自助法**或**留一法**。    3.  在 FP 树上递归挖掘频繁项集。
*   **优点**：只需**两次**扫描数据库，速度通常比 Apriori 快一个数量级。

#### 0.1.4.1 (3) Eclat 算法
*   **原理**：采用**垂直数据格式**（倒排索引），将“事务-项”转化为“项-事务ID列表”。
*   **特点**：通过计算事务 ID 集合的**交集**来快速计算支持度，深度优先搜索。缺点是交集运算量大且占用内存。

### 0.1.5 应用场景

*   **购物篮分析**：发现“啤酒与尿布”通过数据挖掘被摆放在一起销售的规律。
*   **推荐系统**：
    *   **基于关联规则的推荐**：分析用户购买记录，发现 $\{A, B\} \rightarrow \{C\}$ 的规则。如果用户买了 A 和 B，就推荐 C。
    *   相比协同过滤，它更侧重于物品间的强关联逻辑，但可能面临冷启动和计算复杂度高的问题。
*   **其他**：医疗诊断（症状与疾病的关联）、网页浏览分析等。

### 0.1.6 复习建议

根据您的复习资料，关于关联规则建议重点掌握以下内容：
1.  **计算题**：给出一个简单的事务数据集（如5-10条记录），能够手动计算某条规则的 **Support**、**Confidence** 和 **Lift**。
2.  **概念辨析**：理解 Apriori 算法的“剪枝”原理（为什么非频繁项集的超集可以直接删除）。
3.  **算法对比**：知道 Apriori（多次扫描，产生候选集）与 FP-growth（两次扫描，构建树，不产生候选集）的主要区别。