# 1 核心基础概念 (Core Concepts)

这部分建立了机器学习的宏观认知。

1. **机器学习的定义与定位**
    
    - **关系**：机器学习是人工智能（AI）的一个核心分支，是实现AI的手段。数据挖掘利用机器学习算法从海量数据中发现规律。
    - **三要素**：统计学习方法由 **模型（Model）**、**策略（Strategy）** 和 **算法（Algorithm）** 构成。
        - **模型**：要学习的假设空间（如线性函数、神经网络）。
        - **策略**：评估模型好坏的标准（如损失函数）。
        - **算法**：求解最优参数的计算方法（如梯度下降）。
2. **核心定理：没有免费的午餐 (NFL 定理)**
    
    - **内容**：如果对所有可能的问题同等看待，那么所有算法的性能是一样的。脱离具体问题谈论算法好坏没有意义。**不存在万能的算法**，必须结合具体场景选择模型。

# 2 神经网络与深度学习
**多层感知机 (MLP)**：通过引入隐藏层和非线性激活函数（如 Sigmoid, ReLU），解决了感知机无法处理非线性（如 XOR）的问题。
## 2.1 BP神经网络反向传播详解
### 2.1.1 前向传播 (Forward Pass)

假设一个简单的三层网络：输入层 $x$，隐藏层 $h$，输出层 $y$。

- **输入到隐层**：
    - 线性变换：$z_j = \sum_{i} w_{ji}^{(1)} x_i + b_j^{(1)}$
    - 激活输出：$h_j = \sigma(z_j)$ （通常 $\sigma$ 为 Sigmoid 函数）
- **隐层到输出层**：
    - 线性变换：$u_k = \sum_{j} w_{kj}^{(2)} h_j + b_k^{(2)}$
    - 模型输出：$\hat{y}_k = \sigma(u_k)$
- **损失函数** (MSE为例)：$E = \frac{1}{2} \sum_{k} (y_k - \hat{y}_k)^2$

### 2.1.2 反向传播 (Backpropagation) —— 梯度推导核心

我们要更新输出层到隐层的权重 $w_{kj}^{(2)}$，必须求出 $\frac{\partial E}{\partial w_{kj}^{(2)}}$。根据链式法则：

$$ \frac{\partial E}{\partial w_{kj}^{(2)}} = \frac{\partial E}{\partial \hat{y}_k} \cdot \frac{\partial \hat{y}_k}{\partial u_k} \cdot \frac{\partial u_k}{\partial w_{kj}^{(2)}} $$

- **第一项（误差项）**：$\frac{\partial E}{\partial \hat{y}_k} = -(y_k - \hat{y}_k)$
- **第二项（激活导数）**：若 $\sigma$ 是 Sigmoid，$\sigma'(u) = \sigma(u)(1-\sigma(u))$。所以 $\frac{\partial \hat{y}_k}{\partial u_k} = \hat{y}_k(1 - \hat{y}_k)$。
- **第三项（上层输入）**：$\frac{\partial u_k}{\partial w_{kj}^{(2)}} = h_j$

**【结论公式 1】输出层权重梯度：** $$ \Delta w_{kj}^{(2)} = -\eta \cdot \delta_k \cdot h_j $$ 其中 $\delta_k = (y_k - \hat{y}_k) \cdot \hat{y}_k(1 - \hat{y}_k)$。

**【结论公式 2】隐层权重梯度（误差回传）：** 更新输入层到隐层的权重 $w_{ji}^{(1)}$ 时，误差项 $\delta$ 需要从输出层传回来： $$ \delta_j = (\sum_{k} \delta_k w_{kj}^{(2)}) \cdot h_j(1 - h_j) $$ $$ \Delta w_{ji}^{(1)} = -\eta \cdot \delta_j \cdot x_i $$
## 2.2 进阶模型
- **CNN (卷积神经网络)**：核心是**卷积层**（提取局部特征，权重共享）和**池化层**（降维）。适用于图像处理。
- **GAN (生成对抗网络)**：生成器 (G) 和判别器 (D) 相互博弈。G 试图生成逼真样本，D 试图区分真假，最终达到纳什均衡。
- **Transformer**：基于**自注意力机制 (Self-Attention)**，并行计算能力强，是BERT等模型的基础。
- **RNN/LSTM**：用于处理序列数据（如自然语言）。LSTM（长短期记忆网络）通过引入**遗忘门、输入门、输出门**，解决了传统RNN的长距离依赖和梯度消失问题。
### 2.2.1 卷积神经网络 (CNN)

- **卷积层 (Convolution)**：提取局部特征。**权值共享**是核心，减少了参数量。
- **池化层 (Pooling)**：下采样，降低维度，保留主要特征（Max Pooling）或平均特征（Average Pooling），具有平移不变性。
- **典型模型**：
    - **LeNet**：最早用于数字识别。
    - **AlexNet**：引入 ReLU 和 Dropout，使用 GPU 训练。
    - **ResNet**：引入**残差连接 (Shortcut Connection)**，解决了深层网络梯度消失的问题，使得网络可以训练得非常深。

### 2.2.2 循环神经网络 (RNN/LSTM)

- **RNN 问题**：在处理长序列时，存在**梯度消失**或**梯度爆炸**，导致无法记忆长距离信息。
- **LSTM (长短期记忆网络)**：引入了**门控机制** (Gate)。
    - **遗忘门 (Forget Gate)**：决定丢弃多少旧信息。
    - **输入门 (Input Gate)**：决定更新多少新信息。
    - **输出门 (Output Gate)**：决定输出什么状态。
- **GRU**：是 LSTM 的简化版，只有更新门和重置门。
---

# 3 第二部分：支持向量机 (SVM) 的数学深度

## 3.1 核心目标：最大化间隔

SVM 的目标是找到一个超平面 $w^T x + b = 0$，使得两个类别的样本点到平面的距离（几何间隔）最大。

- **几何间隔**：$\gamma = \frac{2}{||w||}$
- **优化目标**：$\max \frac{2}{||w||} \Rightarrow \min \frac{1}{2}||w||^2$
- **约束条件**：$y_i(w^T x_i + b) \ge 1$ (保证所有样本都被正确分类且在间隔外)

## 3.2 对偶问题与拉格朗日乘子法

为了解决上述带约束的凸优化问题，引入拉格朗日乘子 $\alpha_i \ge 0$： $$ L(w, b, \alpha) = \frac{1}{2}||w||^2 - \sum_{i=1}^n \alpha_i [y_i(w^T x_i + b) - 1] $$ 通过对 $w$ 和 $b$ 求偏导并令其为 0，原问题转化为**对偶问题**： $$ \max_{\alpha} \sum_{i=1}^n \alpha_i - \frac{1}{2} \sum_{i=1}^n \sum_{j=1}^n \alpha_i \alpha_j y_i y_j (x_i \cdot x_j) $$ **【重点理解】**：

- **内积的作用**：公式中出现了 $(x_i \cdot x_j)$，这意味着我们只需要知道样本之间的内积，而不需要知道具体的坐标。这为**核函数**的使用提供了数学基础。
- **支持向量**：只有 $\alpha_i > 0$ 的样本才是支持向量，它们决定了超平面的位置。

## 3.3 软间隔与核函数

- **软间隔 (Soft Margin)**：现实数据往往线性不可分，允许少量样本犯错。引入松弛变量 $\xi_i$，优化目标变为 $\min \frac{1}{2}||w||^2 + C \sum \xi_i$。$C$ 是惩罚系数，**$C$ 越大，越不能容忍错误（易过拟合）；$C$ 越小，容错率越高（泛化强）**。
- **核函数 (Kernel Trick)**：将低维不可分数据映射到高维。
    - 常用核：**高斯核 (RBF)** $K(x,z) = \exp(-\gamma ||x-z||^2)$，适用于大多数非线性情况。

---
# 4 决策树与集成学习
## 4.1 决策树
基于树结构进行决策。核心是选择最优划分属性
- **划分标准**：
        - ID3：**信息增益** (Information Gain)，基于信息熵 $Ent(D) = -\sum p_k \log_2 p_k$。
        - C4.5：**信息增益率** (Gain Ratio)，解决ID3偏向多值属性的问题。
        - CART：**基尼指数** (Gini Index)。
## 4.2 集成学习 (Ensemble Learning) 的本质区别

|维度|**Bagging (如随机森林)**|**Boosting (如 AdaBoost, GBDT)**|
|:--|:--|:--|
|**样本采样**|**有放回采样 (Bootstrap)**，每个模型训练集不同且独立|全样本训练，但**样本权重**会随上一轮错误率调整|
|**模型关系**|**并行 (Parallel)**，互不依赖|**串行 (Serial)**，后一个模型基于前一个模型的错误|
|**核心作用**|**降低方差 (Variance)**，提高稳定性，抗过拟合|**降低偏差 (Bias)**，提高拟合能力，将弱模型变强|
|**权重分配**|所有模型投票/平均，权重相等|误差小的模型权重高，误差大的模型权重低|
|**代表算法**|Random Forest|AdaBoost, GBDT, XGBoost|

**AdaBoost 权重更新公式（必记）**：

- 分类器权重：$\alpha_j = \frac{1}{2} \ln(\frac{1-\epsilon_j}{\epsilon_j})$ （错误率 $\epsilon$ 越低，权重 $\alpha$ 越大）
- 样本权重更新：$w_{i}^{(j+1)} = w_{i}^{(j)} e^{-\alpha_j y_i G_j(x_i)}$ （分错的样本，权重变大）

---

# 5 第四部分：朴素贝叶斯与概率图模型

## 5.1 朴素贝叶斯 (Naive Bayes)

- **核心假设**：**特征条件独立假设**。即 $P(X|Y) = P(x_1|Y) \cdot P(x_2|Y) \dots P(x_n|Y)$。这是为了简化联合概率的计算，虽然不完全符合现实，但计算非常高效。
- **拉普拉斯平滑 (Laplacian Smoothing)**：为了解决某个特征在训练集中没出现导致概率为 0 的问题。 $$ P(x_i | y) = \frac{N_{yi} + 1}{N_y + S_i} $$ 其中 $N_{yi}$ 是该特征出现的次数，1 是平滑项，$S_i$ 是该特征可能的取值数量。

## 5.2 贝叶斯网络 (Bayesian Network)

- 解决了朴素贝叶斯假设过强的问题，允许变量间存在依赖关系。
- 使用**有向无环图 (DAG)** 表示依赖关系。
- **计算复杂度**：通过条件独立性，将联合概率分解为局部条件概率的乘积：$P(x_1, \dots, x_n) = \prod P(x_i | \text{Parents}(x_i))$。

---


# 6 损失函数与优化算法的匹配

|任务类型|损失函数 (Loss Function)|输出层激活函数|
|:--|:--|:--|
|**二分类**|**二元交叉熵 (Binary Cross-Entropy)**|Sigmoid|
|**多分类**|**多分类交叉熵 (Categorical Cross-Entropy)**|Softmax|
|**回归**|**均方误差 (MSE, L2 Loss)**|Linear (无) / Identity|
|**抗噪回归**|**Huber Loss** (结合了 L1 和 L2，对异常值不敏感)|-|

**优化算法进化史**：

1. **SGD**：随机梯度下降，震荡大。
2. **Momentum**：加入动量，冲过局部极小值，加速收敛。
3. **AdaGrad**：自适应学习率，累积梯度大则步长小。
4. **Adam**：**目前最常用**，结合了 Momentum 和 RMSprop 的优点，自适应调整每个参数的学习率。
---
# 7 正则化与交叉验证
## 7.1 正则化 (Regularization)

**核心目的**：通过在损失函数中增加一个“惩罚项”（Penalty Term），限制模型的复杂度，从而防止过拟合，实现**结构风险最小化**。

### 7.1.1 数学定义

目标函数 $J(w)$ 由两部分组成： $$ J(w) = \sum_{i=1}^N L(y_i, f(x_i)) + \lambda R(w) $$

- **经验风险** $\sum L(\dots)$：衡量模型对训练数据的拟合程度（如均方误差）。
- **正则化项** $R(w)$：衡量模型的复杂度（通常是权重的范数）。
- **正则化系数** $\lambda$（超参数）：用于平衡拟合程度和模型复杂度。$\lambda$ 越大，惩罚越重，模型越简单（可能欠拟合）；$\lambda$ 越小，越倾向于拟合训练数据（可能过拟合）。

### 7.1.2 L1 正则化 vs. L2 正则化 (【考试重难点】)

这是复习资料中特别标记的对比点。

|特性|**L1 正则化 (Lasso)**|**L2 正则化 (Ridge / 岭回归)**|
|:--|:--|:--|
|**公式**|$R(w) =|w|
|**功能**|**特征选择**，产生**稀疏解**（某些权重直接变为0）|**权重衰减**，使权重趋向于0但不为0，产生**平滑解**|
|**几何解释**|约束区域是**菱形**（Diamond）。等值线容易与菱形的“角”（坐标轴）相交，导致 $w_i=0$|约束区域是**圆形**。等值线与圆相切的点通常不在坐标轴上，只是让 $w_i$ 变小|
|**概率解释**|对应参数服从**拉普拉斯分布** (Laplace) 的先验|对应参数服从**高斯分布** (Gaussian) 的先验|
|**求解方法**|在 0 处不可导，常用**坐标轴下降法**|处处可导，可用梯度下降或解析解（如正规方程）|

- **弹性网络 (Elastic Net)**：结合了 L1 和 L2，公式为 $R(w) = \rho ||w||_1 + \frac{1-\rho}{2} ||w||_2^2$。

### 7.1.3 深度学习中的正则化

在神经网络中，除了 L1/L2 正则化，**Dropout** 也是一种常用的正则化手段。它通过随机“丢弃”部分神经元，降低神经元之间的耦合度，从而防止过拟合。
## 7.2 二、 交叉验证 (Cross Validation)

**核心目的**：在数据量有限的情况下，通过对数据集的多次划分，评估模型的泛化能力，并用于**模型选择**和**超参数调优**（如确定正则化系数 $\lambda$）。

### 7.2.1 留出法 (Holdout)

- **方法**：直接将数据集随机划分为两个互斥的集合：训练集和测试集（例如 7:3 划分）。
- **缺点**：评估结果依赖于具体的划分方式，数据利用率不高。

### 7.2.2 k 折交叉验证 (k-Fold CV) —— 【实验重点】

- **步骤**：
    1. 将数据集随机划分为 $k$ 个大小相似的互斥子集。
    2. 进行 $k$ 次训练和测试：每次取 **1个** 子集作为验证集，其余 **$k-1$ 个** 子集作为训练集。
    3. 计算 $k$ 次测试结果的**平均值**，作为该模型的性能指标。
- **优点**：比留出法更稳定，评估结果更可靠，数据利用率高。通常 $k$ 取 10。
- **分层交叉验证 (Stratified k-Fold)**：保持类别比例与总体一致，适用于样本不平衡情况。

### 7.2.3 留一法 (Leave-One-Out, LOO)

- **方法**：$k$ 折交叉验证的特例，其中 $k$ 等于样本总数 $N$。每次只留 **1个** 样本做测试。
- **特点**：评估结果最准确（使用几乎所有数据训练），但计算开销极大。

### 7.2.4 自助法 (Bootstrapping)

- **方法**：通过**有放回**的随机采样生成训练集。约 36.8% 的样本从未被采到（包外数据），可用作测试集。
- **适用场景**：数据集较小且难以划分时。

---

## 7.3 正则化与交叉验证的结合应用

在实际建模（如 RidgeCV, LassoCV）中，通常结合两者来寻找最优模型：

1. **超参数调优**：正则化系数 $\lambda$ 是一个超参数，不能通过训练直接得到，必须人工指定。
2. **过程**：
    - 设定一系列候选的 $\lambda$ 值（如 0.1, 1, 10）。
    - 对每一个 $\lambda$，使用 **k 折交叉验证** 计算模型的平均误差。
    - 选择**平均误差最小**对应的那个 $\lambda$ 作为最终参数。
    - 使用该最优 $\lambda$ 在全部训练数据上重新训练模型。


---

# 8 K-Means 与 GMM（无监督学习）

- **K-Means**：
    - 硬聚类（样本非此即彼）。
    - 基于距离（欧氏距离），适合凸形簇。
    - 缺点：需预设 K 值，对初始值敏感。
- **高斯混合模型 (GMM)**：
    - 软聚类（输出样本属于各簇的概率）。
    - 假设数据由多个高斯分布混合而成。
    - 使用 **EM算法 (期望最大化)** 求解：E步估计类别概率，M步更新高斯参数（均值、方差）。
---
# 9 梯度下降
核心公式：$\theta_{t+1} = \theta_t - \eta \nabla J(\theta)$。

- **批量梯度下降 (BGD)**：用所有样本计算梯度，准但慢。
- **随机梯度下降 (SGD)**：用一个样本计算梯度，快但震荡。
- **小批量梯度下降 (Mini-batch)**：折中方案，深度学习常用。

## 9.1 梯度下降法与其他算法的联系

在做题时，看到以下算法要立刻联想到梯度下降：

1. **感知机 (Perceptron)**：其参数更新规则 w←w+ηyi​xi​ 本质上就是随机梯度下降（SGD）在感知机损失函数上的应用,。

2. **BP神经网络 (Backpropagation)**：**必考计算题**。BP算法的核心就是利用链式法则计算损失函数对每个权重的梯度，然后**使用梯度下降法更新权重**,,。

3. **逻辑回归 (Logistic Regression)**：由于没有解析解（无法像线性回归那样直接算出公式解），必须使用梯度下降或牛顿法迭代求解。

4. **Lasso回归 (L1正则化)**：注意，由于L1范数 ∣w∣ 在0点不可导，**不能直接使用标准梯度下降**，通常使用**坐标轴下降法 (Coordinate Descent)** 或次梯度法,。

5. 做题与复习策略总结

• **计算题**：如果考到“手动更新参数”，务必死记公式$θ_{new}​=θ_{old}​−η×Gradient$。特别注意梯度的符号，通常是**减去**梯度,。

• **概念题**：区分 BGD（全量，稳但慢）、SGD（单个，快但震荡）、MBGD（小批量，折中）的区别。

• **应用题**：如果问“为什么训练过程中Loss震荡不下降？”，原因可能是**学习率过大** 或使用了 **SGD**。
