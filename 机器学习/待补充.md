# 1 核心基础概念 (Core Concepts)
1. **机器学习的定义与定位**
    
    - **关系**：机器学习是人工智能（AI）的一个核心分支，是实现AI的手段。数据挖掘利用机器学习算法从海量数据中发现规律。
    - **三要素**：统计学习方法由 **模型（Model）**、**策略（Strategy）** 和 **算法（Algorithm）** 构成。
        - **模型**：要学习的假设空间（如线性函数、神经网络）。
        - **策略**：评估模型好坏的标准（如损失函数）。
        - **算法**：求解最优参数的计算方法（如梯度下降）。
2. **核心定理：没有免费的午餐 (NFL 定理)**
    - **内容**：如果对所有可能的问题同等看待，那么所有算法的性能是一样的。脱离具体问题谈论算法好坏没有意义。**不存在万能的算法**，必须结合具体场景选择模型。
3. ==**过拟合与欠拟合**==
	- 过拟合
		- **模型复杂度过高**（参数过多、结构复杂）
		- **训练数据不足**
		- **有过量噪声与异常值**
		- **缺乏具有代表性的样本**
		- **训练过度**
		- **从偏差-方差角度看**：过拟合对应的是**高方差（High Variance）**(训练集误差**很小**;测试集误差**很大**)。这意味着模型对训练数据的微小变动非常敏感，将数据中的随机扰动也纳入了模型中。
	- 欠拟合
		- **模型复杂度过低**（模型本身的拟合能力不足）
		- **特征数量或质量不足**（解决思路通常是提高特征的数量和质量。）
		- **训练不足**
		- **从偏差-方差角度看**：欠拟合对应的是**高偏差（High Bias）**(训练集和测试集误差**都大**)。这意味着模型对真实规律的刻画能力不足，预测值与真实值之间存在较大的系统性偏差。
# 2 神经网络与深度学习
**多层感知机 (MLP)**：通过引入隐藏层和非线性激活函数（如 Sigmoid, ReLU），解决了感知机无法处理非线性（如 XOR）的问题。
## 2.1 BP神经网络反向传播详解
### 2.1.1 前向传播 (Forward Pass)
假设一个简单的三层网络：输入层 $x$，隐藏层 $h$，输出层 $y$。
- **输入到隐层**：
    - 线性变换：$z_j = \sum_{i} w_{ji}^{(1)} x_i + b_j^{(1)}$
    - [[几种激活函数及其特点|激活]]输出：$h_j = \sigma(z_j)$ （通常 $\sigma$ 为 Sigmoid 函数，但是和tanh一样易饱和，可能会导致梯度消失）
- **隐层到输出层**：
    - 线性变换：$u_k = \sum_{j} w_{kj}^{(2)} h_j + b_k^{(2)}$
    - 模型输出：$\hat{y}_k = \sigma(u_k)$
- **损失函数** (MSE为例)：$E = \frac{1}{2} \sum_{k} (y_k - \hat{y}_k)^2$
### 2.1.2 反向传播 (Backpropagation) —— 梯度推导核心
我们要更新输出层到隐层的权重 $w_{kj}^{(2)}$，必须求出 $\frac{\partial E}{\partial w_{kj}^{(2)}}$。根据链式法则：
$$ \frac{\partial E}{\partial w_{kj}^{(2)}} = \frac{\partial E}{\partial \hat{y}_k} \cdot \frac{\partial \hat{y}_k}{\partial u_k} \cdot \frac{\partial u_k}{\partial w_{kj}^{(2)}} $$
- **第一项（误差项）**：$\frac{\partial E}{\partial \hat{y}_k} = -(y_k - \hat{y}_k)$
- **第二项（激活导数）**：若 $\sigma$ 是 Sigmoid，$\sigma'(u) = \sigma(u)(1-\sigma(u))$。所以 $\frac{\partial \hat{y}_k}{\partial u_k} = \hat{y}_k(1 - \hat{y}_k)$。
- **第三项（上层输入）**：$\frac{\partial u_k}{\partial w_{kj}^{(2)}} = h_j$
**【结论公式 1】输出层权重梯度：** $$ \Delta w_{kj}^{(2)} = -\eta \cdot \delta_k \cdot h_j $$ 其中 $\delta_k = (y_k - \hat{y}_k) \cdot \hat{y}_k(1 - \hat{y}_k)$。
**【结论公式 2】隐层权重梯度（误差回传）：** 更新输入层到隐层的权重 $w_{ji}^{(1)}$ 时，误差项 $\delta$ 需要从输出层传回来： $$ \delta_j = (\sum_{k} \delta_k w_{kj}^{(2)}) \cdot h_j(1 - h_j) $$ $$ \Delta w_{ji}^{(1)} = -\eta \cdot \delta_j \cdot x_i $$
## 2.2 进阶模型
- **CNN (卷积神经网络)**：核心是**卷积层**（提取局部特征，权重共享）和**池化层**（降维）。适用于图像处理。
- **GAN (生成对抗网络)**：生成器 (G) 和判别器 (D) 相互博弈。G 试图生成逼真样本，D 试图区分真假，最终达到纳什均衡。
- **Transformer**：基于**自注意力机制 (Self-Attention)**，并行计算能力强，是BERT等模型的基础。
- **RNN/LSTM**：用于处理序列数据（如自然语言）。LSTM（长短期记忆网络）通过引入**遗忘门、输入门、输出门**，解决了传统RNN的长距离依赖和梯度消失问题。
	- 看清楚RNN是*多对一*还是*几对几*，以此判断其结构。
	- 单向RNN依赖于过去，双向RNN依赖会有未来信息介入
	- 在LSTM中：所有门的维度=隐藏状态的维度
### 2.2.1 卷积神经网络 (CNN)
- **卷积层 (Convolution)**：提取局部特征。**权值共享**是核心，减少了参数量。
- **池化层 (Pooling)**：下采样，降低维度，保留主要特征（Max Pooling）或平均特征（Average Pooling），具有平移不变性。
- **典型模型**：
    - **LeNet**：最早用于数字识别。
    - **AlexNet**：引入 ReLU 和 Dropout，使用 GPU 训练。
    - **ResNet**：引入**残差连接 (Shortcut Connection)**，解决了深层网络梯度消失的问题，使得网络可以训练得非常深。
### 2.2.2 循环神经网络 (RNN/LSTM)
- **RNN 问题**：在处理长序列时，存在**梯度消失**或**梯度爆炸**，导致无法记忆长距离信息。
- **LSTM (长短期记忆网络)**：引入了**门控机制** (Gate)。
    - **遗忘门 (Forget Gate)**：决定丢弃多少旧信息。
    - **输入门 (Input Gate)**：决定更新多少新信息。
    - **输出门 (Output Gate)**：决定输出什么状态。
- **GRU**：是 LSTM 的简化版，只有更新门和重置门。
---
# 3 第二部分：支持向量机 (SVM) 的数学深度（待加KTT条件

## 3.1 核心目标：最大化间隔
SVM 的目标是找到一个超平面 $w^T x + b = 0$，使得两个类别的样本点到平面的距离（几何间隔）最大。
- **几何间隔**：$\gamma = \frac{2}{||w||}$
- **优化目标**：$\max \frac{2}{||w||} \Rightarrow \min \frac{1}{2}||w||^2$
- **约束条件**：$y_i(w^T x_i + b) \ge 1$ (保证所有样本都被正确分类且在间隔外)
## 3.2 对偶问题与拉格朗日乘子法
为了解决上述带约束的凸优化问题，引入拉格朗日乘子 $\alpha_i \ge 0$： $$ L(w, b, \alpha) = \frac{1}{2}||w||^2 - \sum_{i=1}^n \alpha_i [y_i(w^T x_i + b) - 1] $$ 通过对 $w$ 和 $b$ 求偏导并令其为 0，原问题转化为**对偶问题**： $$ \max_{\alpha} \sum_{i=1}^n \alpha_i - \frac{1}{2} \sum_{i=1}^n \sum_{j=1}^n \alpha_i \alpha_j y_i y_j (x_i \cdot x_j) $$
最终模型：$$
f(x)=w^Tx+b=\sum_{i=1}^ma_{i}a_{j}x^T_{i}x+b
$$
在凸优化问题中带来了如下KKT条件：
$$
\begin{cases}
\alpha_i \ge 0,0\\
1 - y_i f(x_i) \le 0, \\
\alpha_i\bigl(1 - y_i f(x_i)\bigr) = 0.
\end{cases}
$$
导致了$\alpha=0或者y_if(x_{i})=1$从而可以说，支持向量机的解有*稀疏性*。

**【重点理解】**：
- **内积的作用**：公式中出现了 $(x_i \cdot x_j)$，这意味着我们只需要知道样本之间的内积，而不需要知道具体的坐标。这为**核函数**的使用提供了数学基础。
- **支持向量**：只有 $\alpha=0或者y_if(x_{i})=1$ 的样本才是支持向量，它们决定了超平面的位置。
	- 支持向量是那些“卡住最大间隔”的样本点；  
	- 删除非支持向量，最优超平面不变；  
	- 删除一个支持向量，最优超平面就会改变
## 3.3 软间隔与核函数
- **软间隔 (Soft Margin)**：现实数据往往线性不可分，允许少量样本犯错。引入松弛变量 $\xi_i$，优化目标变为 $\min \frac{1}{2}||w||^2 + C \sum \xi_i$。$C$ 是惩罚系数，**$C$ 越大，越不能容忍错误（易过拟合）；$C$ 越小，容错率越高（泛化强）**。$1-\xi_i$是我们求到的最小间隔。 
- **核函数 (Kernel Trick)**：将低维不可分数据映射到高维。
    - 常用核：**高斯核 (RBF)** $K(x,z) = \exp(-\gamma ||x-z||^2)$，适用于大多数非线性情况。
---
# 4 决策树与集成学习
候选划分（候选测试 / 候选问题）数量：候选问题数 = **属性个数**
## 4.1 决策树（剪枝相关知识点待补充
基于树结构进行决策。核心是选择最优划分属性
- **划分标准**：
        - ID3：**信息增益** (Information Gain)，基于信息熵 $Ent(D) = -\sum p_k \log_2 p_k$。
                - 信息熵：度量随机变量的不确定性，熵越大越不确定。（当X某个取1时，信息熵最低为0，X的概率均匀分布时，信息熵最大
        - C4.5：**信息增益率** (Gain Ratio)，解决ID3偏向多值属性的问题。
        - CART：**基尼指数** (Gini Index)。
## 4.2 集成学习 (Ensemble Learning) 的本质区别

| 维度       | **Bagging (如随机森林)**                | **Boosting (如 AdaBoost, GBDT)** |
| :------- | :--------------------------------- | :------------------------------ |
| **样本采样** | **有放回采样 (Bootstrap)**，每个模型训练集不同且独立 | 全样本训练，但**样本权重**会随上一轮错误率调整       |
| **模型关系** | **并行 (Parallel)**，互不依赖             | **串行 (Serial)**，后一个模型基于前一个模型的错误 |
| **核心作用** | **降低方差 (Variance)**，提高稳定性，抗过拟合     | **降低偏差 (Bias)**，提高拟合能力，将弱模型变强   |
| **权重分配** | 所有模型投票/平均，权重相等                     | 误差小的模型权重高，误差大的模型权重低             |
| **代表算法** | Random Forest                      | AdaBoost, GBDT, XGBoost         |

**AdaBoost 权重更新公式（必记）**：
- 分类器权重：$\alpha_j = \frac{1}{2} \ln(\frac{1-\epsilon_j}{\epsilon_j})$ （错误率 $\epsilon$ 越低，权重 $\alpha$ 越大）
- 样本权重更新：$w_{i}^{(j+1)} = w_{i}^{(j)} e^{-\alpha_j y_i G_j(x_i)}$ （分错的样本，权重变大）

---
# 5 朴素贝叶斯与概率图模型（待加高斯

## 5.1 朴素贝叶斯 (Naive Bayes)

- **核心假设**：**特征条件独立假设**。即 $P(X|Y) = P(x_1|Y) \cdot P(x_2|Y) \dots P(x_n|Y)$。这是为了简化联合概率的计算，虽然不完全符合现实，但计算非常高效。
- **拉普拉斯平滑 (Laplacian Smoothing)**：为了解决某个特征在训练集中没出现导致概率为 0 的问题。 $$ P(x_i | y) = \frac{N_{yi} + 1}{N_y + S_i} $$ 其中 $N_{yi}$ 是该特征出现的次数，1 是平滑项，$S_i$ 是该特征可能的取值数量。
## 5.2 贝叶斯网络 (Bayesian Network)
- 解决了朴素贝叶斯假设过强的问题，允许变量间存在依赖关系。
- 使用**有向无环图 (DAG)** 表示依赖关系。
- **计算复杂度**：通过条件独立性，将联合概率分解为局部条件概率的乘积：$P(x_1, \dots, x_n) = \prod P(x_i | \text{Parents}(x_i))$
# 6 参数估计
## 6.1 最大似然估计 (Maximum Likelihood Estimation, MLE)
**核心思想**： 最大似然估计是一种经典的“点估计”方法，它不考虑先验知识，完全依赖于当前的观测数据。其核心思想是：找到一组参数 $\theta$，使得在该参数下，**观测数据 $X$ 出现的可能性（似然）最大**,。
**数学表达**： 假设观测数据 $X$ 的分布函数为 $P(X|\theta)$，MLE 的目标是最大化似然函数 $L(\theta)$： $$ \hat{\theta}_{MLE} = \arg\max_{\theta} P(X|\theta) $$ 为了计算方便（防止连乘导致数值下溢），通常对似然函数取对数，将乘积转化为求和，即最大化**对数似然函数**： $$ \hat{\theta}_{MLE} = \arg\max_{\theta} \sum \log P(x_i|\theta) $$ 

---
## 6.2 最大后验估计 (Maximum A Posteriori, MAP)
**核心思想**： MAP 是**贝叶斯估计**的一种特定形式（点估计形式）。它不仅考虑观测数据（似然），还引入了参数 $\theta$ 的**先验知识（Prior）**。其核心目标是：找到一组参数 $\theta$，使得在已知观测数据 $X$ 的情况下，**参数 $\theta$ 出现的概率（后验概率）最大**,。
**结合贝叶斯公式的推导**： 根据贝叶斯定理，后验概率 $P(\theta|X)$ 可以表示为： $$ P(\theta|X) = \frac{P(X|\theta)P(\theta)}{P(X)} $$
- $P(X|\theta)$：**似然函数**（Likelihood），来自观测数据。
- $P(\theta)$：**先验概率**（Prior），来自历史经验或领域知识。
- $P(X)$：边缘概率，对于参数 $\theta$ 的优化来说是常数（因为数据 $X$ 已经确定）。
**最大化联合概率 ($X$ 与 $\theta$)**： MAP 的目标是最大化后验概率 $P(\theta|X)$。由于分母 $P(X)$ 与 $\theta$ 无关，**最大化后验概率等价于最大化分子**： $$ \hat{\theta}_{MAP} = \arg\max_{\theta} P(\theta|X) = \arg\max_{\theta} \frac{P(X|\theta)P(\theta)}{P(X)} $$ $$ \Rightarrow \hat{\theta}_{MAP} = \arg\max_{\theta} P(X|\theta)P(\theta) $$ 而分子 $P(X|\theta)P(\theta)$ 正是 $\theta$ 与 $X$ 的**联合概率** $P(X, \theta)$。 因此，**最大后验估计本质上就是在最大化参数 $\theta$ 与观测数据 $X$ 的联合概率**,。
**对数形式**： 为了求解方便，通常也转化为对数形式，目标函数变成了“对数似然 + 对数先验”： $$ \hat{\theta}_{MAP} = \arg\max_{\theta} (\log P(X|\theta) + \log P(\theta)) $$ 这解释了为什么 MAP 常被视为在 MLE 的基础上增加了**正则化项**（$\log P(\theta)$ 对应正则项，限制模型复杂度）,。

---
## 6.3 三、 两者对比总结

| 特性          | **最大似然估计 (MLE)**                                                  | **最大后验估计 (MAP)**                                               |
| :---------- | :---------------------------------------------------------------- | :------------------------------------------------------------- |
| **优化目标**    | 最大化 **似然函数** $P(X                                                 | \theta)$                                                       |
| **先验知识**    | 假设没有先验知识（或认为先验是均匀分布）                                              | 引入 **先验概率** $P(\theta)$                                        |
| **看待参数的观点** | 参数 $\theta$ 是**固定**但未知的常量                                         | 参数 $\theta$ 是**随机变量**，服从某种分布                                   |
| **公式关系**    | $\hat{\theta}_{MLE} = \arg\max_{\theta} \sum \log P(x_i\|\theta)$ | $\hat{\theta}_{MAP} = \arg\max_{\theta} P(X\|\theta)P(\theta)$ |
| **应用场景**    | 数据量较大，先验影响较小的情况                                                   | 数据量较小，或有明确先验信息（如正则化）的情况                                        |

**结论**：如果参数 $\theta$ 的先验分布 $P(\theta)$ 是均匀分布（即所有取值概率相等），那么 MAP 就退化为 MLE。MAP 可以看作是带有“偏见”（先验）的 MLE,。

---
# 7 损失函数与优化算法的匹配

|任务类型|损失函数 (Loss Function)|输出层激活函数|
|:--|:--|:--|
|**二分类**|**二元交叉熵 (Binary Cross-Entropy)**|Sigmoid|
|**多分类**|**多分类交叉熵 (Categorical Cross-Entropy)**|Softmax|
|**回归**|**均方误差 (MSE, L2 Loss)**|Linear (无) / Identity|
|**抗噪回归**|**Huber Loss** (结合了 L1 和 L2，对异常值不敏感)|-|

**优化算法进化史**：
1. **SGD**：随机梯度下降，震荡大。
2. **Momentum**：加入动量，冲过局部极小值，加速收敛。
3. **AdaGrad**：自适应学习率，累积梯度大则步长小。
4. **Adam**：**目前最常用**，结合了 Momentum 和 RMSprop 的优点，自适应调整每个参数的学习率。
---
# 8 正则化与交叉验证
## 8.1 正则化 (Regularization)

**核心目的**：通过在损失函数中增加一个“惩罚项”（Penalty Term），限制模型的复杂度，从而防止过拟合，实现**结构风险最小化**。
### 8.1.1 数学定义

目标函数 $J(w)$ 由两部分组成： $$ J(w) = \sum_{i=1}^N L(y_i, f(x_i)) + \lambda R(w) $$

- **经验风险** $\sum L(\dots)$：衡量模型对训练数据的拟合程度（如均方误差）。
- **正则化项** $R(w)$：衡量模型的复杂度（通常是权重的范数）。
- **正则化系数** $\lambda$（超参数）：用于平衡拟合程度和模型复杂度。$\lambda$ 越大，惩罚越重，模型越简单（可能欠拟合）；$\lambda$ 越小，越倾向于拟合训练数据（可能过拟合）。
### 8.1.2 L1 正则化 vs. L2 正则化 (【考试重难点】)

| 特性       | **L1 正则化 (Lasso)**                                   | **L2 正则化 (Ridge / 岭回归)**                              |
| :------- | :--------------------------------------------------- | :---------------------------------------------------- |
| **公式**   | $R(w) =                                              | w                                                     |
| **功能**   | **特征选择**，产生**稀疏解**（某些权重直接变为0）                        | **权重衰减**，使权重趋向于0但不为0，产生**平滑解**，惩罚大的单个分量               |
| **几何解释** | 约束区域是**菱形**（Diamond）。等值线容易与菱形的“角”（坐标轴）相交，导致 $w_i=0$  | 约束区域是**圆形**。等值线与圆相切的点通常不在坐标轴上，只是让 $w_i$ 变小            |
| **概率解释** | 对应参数服从**拉普拉斯分布** (Laplace) 的先验                       | 对应参数服从**高斯分布** (Gaussian) 的先验                         |
| **求解方法** | 在 0 处不可导，常用**坐标轴下降法**                                | 处处可导，可用梯度下降或解析解（如正规方程）                                |
| **结果**   | **稀疏解**（很多分量被压到 0）、自动特征选择、非零分量仍然不均衡、对高度相关特征：容易“只留一个” | ❌**不稀疏**（几乎没有精确 0）、**分量取值均衡**、权重整体变小（但都存在）、 模型稳定、抗噪声强 |
 常见考点对应关系
- **“稀疏 / 非零分量少”** → L0 / L1
- **“自动特征选择”** → L1
- **“分量取值均衡 / 稠密”** → **L2**
- **“稳定 / 抗噪 / 防过拟合”** → L2
- **“相关特征一起保留”** → L2

- **弹性网络 (Elastic Net)**：结合了 L1 和 L2，公式为 $R(w) = \rho ||w||_1 + \frac{1-\rho}{2} ||w||_2^2$。
### 8.1.3 深度学习中的正则化
在神经网络中，除了 L1/L2 正则化，**Dropout** 也是一种常用的正则化手段。它通过随机“丢弃”部分神经元，降低神经元之间的耦合度，从而防止过拟合。
## 8.2 交叉验证 (Cross Validation)
**核心目的**：在数据量有限的情况下，通过对数据集的多次划分，评估模型的泛化能力，并用于**模型选择**和**超参数调优**（如确定正则化系数 $\lambda$）。
### 8.2.1 留出法 (Holdout)
- **方法**：直接将数据集随机划分为两个互斥的集合：训练集和测试集（例如 7:3 划分）。
- **缺点**：评估结果依赖于具体的划分方式，数据利用率不高。
### 8.2.2 k 折交叉验证 (k-Fold CV) —— 【实验重点】
- **步骤**：
    1. 将数据集随机划分为 $k$ 个大小相似的互斥子集。
    2. 进行 $k$ 次训练和测试：每次取 **1个** 子集作为验证集，其余 **$k-1$ 个** 子集作为训练集。
    3. 计算 $k$ 次测试结果的**平均值**，作为该模型的性能指标。
- **优点**：比留出法更稳定，评估结果更可靠，数据利用率高。通常 $k$ 取 10。
- **分层交叉验证 (Stratified k-Fold)**：保持类别比例与总体一致，适用于样本不平衡情况。
### 8.2.3 留一法 (Leave-One-Out, LOO)
- **方法**：$k$ 折交叉验证的特例，其中 $k$ 等于样本总数 $N$。每次只留 **1个** 样本做测试。
- **特点**：评估结果最准确（使用几乎所有数据训练），但计算开销极大。
### 8.2.4 自助法 (Bootstrapping)
- **方法**：通过**有放回**的随机采样生成训练集。约 36.8% 的样本从未被采到（包外数据），可用作测试集。
- **适用场景**：数据集较小且难以划分时。

---

## 8.3 正则化与交叉验证的结合应用
在实际建模（如 RidgeCV, LassoCV）中，通常结合两者来寻找最优模型：
1. **超参数调优**：正则化系数 $\lambda$ 是一个超参数，不能通过训练直接得到，必须人工指定。
2. **过程**：
    - 设定一系列候选的 $\lambda$ 值（如 0.1, 1, 10）。
    - 对每一个 $\lambda$，使用 **k 折交叉验证** 计算模型的平均误差。
    - 选择**平均误差最小**对应的那个 $\lambda$ 作为最终参数。
    - 使用该最优 $\lambda$ 在全部训练数据上重新训练模型。
---
# 9 K-Means 与 GMM（无监督学习）
- **K-Means**：
    - 硬聚类（样本非此即彼）。
    - 基于距离（欧氏距离），适合凸形簇。
    - 缺点：需预设 K 值，对初始值敏感。
- **高斯混合模型 (GMM)**：
    - 软聚类（输出样本属于各簇的概率）。
    - 假设数据由多个高斯分布混合而成。
    - 使用 **EM算法 (期望最大化)** 求解：E步估计类别概率，M步更新高斯参数（均值、方差）。
---
# 10 梯度下降
核心公式：$\theta_{t+1} = \theta_t - \eta \nabla J(\theta)$。
- **批量梯度下降 (BGD)**：用所有样本计算梯度，准但慢。
- **随机梯度下降 (SGD)**：用一个样本计算梯度，快但震荡。
- **小批量梯度下降 (Mini-batch)**：折中方案，深度学习常用。

## 10.1 梯度下降法与其他算法的联系
在做题时，看到以下算法要立刻联想到梯度下降：
1. **感知机 (Perceptron)**：其参数更新规则 w←w+ηyi​xi​ 本质上就是随机梯度下降（SGD）在感知机损失函数上的应用,。
2. **BP神经网络 (Backpropagation)**：**必考计算题**。BP算法的核心就是利用链式法则计算损失函数对每个权重的梯度，然后**使用梯度下降法更新权重**,,。
3. **逻辑回归 (Logistic Regression)**：由于没有解析解（无法像线性回归那样直接算出公式解），必须使用梯度下降或牛顿法迭代求解。
4. **Lasso回归 (L1正则化)**：注意，由于L1范数 ∣w∣ 在0点不可导，**不能直接使用标准梯度下降**，通常使用**坐标轴下降法 (Coordinate Descent)** 或次梯度法,。
5. 做题与复习策略总结
	• **计算题**：如果考到“手动更新参数”，务必死记公式$θ_{new}​=θ_{old}​−η×Gradient$。特别注意梯度的符号，通常是**减去**梯度,。
	• **概念题**：区分 BGD（全量，稳但慢）、SGD（单个，快但震荡）、MBGD（小批量，折中）的区别。
	• **应用题**：如果问“为什么训练过程中Loss震荡不下降？”，原因可能是**学习率过大** 或使用了 **SGD**。

# 11 模型评估与分析 (Evaluation)
## 11.1 评估指标 (Evaluation Metrics)

评估指标用于量化模型在测试集上的表现。根据任务类型（分类或回归），指标有所不同。
### 11.1.1 分类任务指标
- **混淆矩阵 (Confusion Matrix)**：是许多指标的基础，根据预测类别与真实类别的组合分为四种情况,：
    - **TP (True Positive)**：真正例（预测为正，实际为正）。
    - **FP (False Positive)**：假正例（预测为正，实际为负）。
    - **FN (False Negative)**：假反例（预测为负，实际为正）。
    - **TN (True Negative)**：真反例（预测为负，实际为负）。
- **基础指标**：
    - **准确率 (Accuracy)**：分类正确的样本占总样本的比例。公式：$Accuracy = \frac{TP+TN}{TP+FP+FN+TN}$。
    - **错误率 (Error Rate)**：分类错误的样本占比。公式：$E = 1 - Accuracy$。
    - **查准率 (Precision)**：预测为正例的样本中，实际为正例的比例。公式：$P = \frac{TP}{TP+FP}$,。
    - **查全率 (Recall)**：实际为正例的样本中，被正确预测出来的比例。公式：$R = \frac{TP}{TP+FN}$,。
- **综合指标**：
    - **F1值 (F1-Score)**：查准率和查全率的调和平均数，用于平衡两者。公式：$F1 = \frac{2 \times P \times R}{P + R}$,。
    - **宏平均 (Macro-F1) 与 微平均 (Micro-F1)**：在多分类问题中，Macro是先算各类的F1再求平均（受小类别影响大），Micro是先汇总各类的TP/FP/FN再算F1（受大类别影响大）。
- **ROC与AUC**：
    - **ROC曲线**：横轴为假正例率 (FPR)，纵轴为真正例率 (TPR)。曲线越靠近左上角越好,。
    - **AUC (Area Under Curve)**：ROC曲线下的面积。AUC值越大，说明分类器排序预测的能力越强（即正样本的预测得分大于负样本的概率）,。
### 11.1.2 回归任务指标
- **均方误差 (MSE)**：预测值与真实值差值的平方和的平均值。公式：$MSE = \frac{1}{N}\sum (y_i - \hat{y}_i)^2$,。
- **平均绝对误差 (MAE)**：预测值与真实值差值的绝对值的平均值。公式：$MAE = \frac{1}{N}\sum |y_i - \hat{y}_i|$,。
- **$R^2$ (决定系数)**：衡量模型拟合数据的程度，值越接近1越好。公式：$R^2 = 1 - \frac{SS_{res}}{SS_{tot}}$,。

---

## 11.2 偏差-方差分解 (Bias-Variance Decomposition)

这是解释算法泛化性能的重要工具，它将学习算法的期望泛化误差分解为三个部分,。
### 11.2.1 分解公式

对回归任务，泛化误差可分解为： $$ E(f;D) = bias^2(x) + var(x) + \epsilon^2 $$
- **偏差 (Bias)**：$bias^2(x) = (\bar{f}(x) - y)^2$。度量了学习算法的期望预测与真实结果的偏离程度，刻画了算法本身的**拟合能力**,。
- **方差 (Variance)**：$var(x) = E[(f(x;D) - \bar{f}(x))^2]$。度量了同样大小的训练集的变动所导致的对学习性能的影响，刻画了**数据扰动所造成的影响**（模型稳定性）,。
- **噪声 (Noise)**：$\epsilon^2$。表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，刻画了**学习问题本身的难度**,。

### 11.2.2 偏差-方差窘境 (Bias-Variance Dilemma)

两者通常存在冲突,：

- **欠拟合 (Underfitting)**：模型过于简单（如线性模型拟合复杂曲线），此时**偏差主导**，训练误差大。
- **过拟合 (Overfitting)**：模型过于复杂（如高阶多项式），对训练数据拟合得太好，此时**方差主导**，训练数据微小的变化都会导致模型预测的巨大变化。
- **目标**：寻找偏差与方差的平衡点，使总误差最小。

---

## 11.3 交叉验证 (Cross Validation)

交叉验证是一种评估模型泛化能力、选择模型和调整超参数的统计学方法，旨在充分利用有限的数据,。
### 11.3.1 留出法 (Holdout)
- **原理**：直接将数据集 $D$ 划分为两个互斥的集合：训练集 $S$ 和测试集 $T$（例如 7:3 划分）。
- **缺点**：评估结果依赖于具体的划分方式，且训练集小于原始数据集，可能导致评估偏差,。
### 11.3.2 k折交叉验证 (k-Fold Cross Validation) ——【实验重点】

- **原理**：将数据集 $D$ 随机划分为 $k$ 个大小相似的互斥子集。每次用 $k-1$ 个子集的并集作为训练集，余下的那个子集作为测试集。重复 $k$ 次，最终返回 $k$ 个测试结果的均值,。
- **优点**：评估结果比留出法更稳定、更可靠。
- **特例**：**留一法 (Leave-One-Out, LOO)**。当 $k=N$（样本总数）时，每次只留一个样本做测试。评估结果最准确，但计算开销最大,。

### 11.3.3 分层交叉验证 (Stratified k-Fold)

- **原理**：在划分数据时，保证每个子集中各类别的样本比例与总体数据集中的比例一致。这在处理**类别不平衡**数据时非常重要。

### 11.3.4 自助法 (Bootstrapping)

- **原理**：通过**有放回**的采样产生训练集。假设数据集包含 $N$ 个样本，有放回采样 $N$ 次，约有 $36.8$% 的样本未被采到（$\lim_{n\to\infty}(1-1/n)^n \approx 1/e \approx 0.368$）。
- **包外估计 (Out-of-bag estimate)**：未被采到的样本用作测试集。
- **适用场景**：数据集较小难以划分训练/测试集时,,。